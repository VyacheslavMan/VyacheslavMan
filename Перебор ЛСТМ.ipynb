{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1141,
     "status": "ok",
     "timestamp": 1641026265024,
     "user": {
      "displayName": "Slava Manevich",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "03367332962160017370"
     },
     "user_tz": -180
    },
    "id": "Ula51kGaugLr",
    "outputId": "f2129da5-7727-4140-c681-7a5da4ce0998"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "file='C:/Users/VIP13/Downloads/Все по нейронкам/all_rv.xlsx'\n",
    "\n",
    "# Load spreadsheet\n",
    "xl = pd.ExcelFile(file)\n",
    "\n",
    "# Print the sheet names\n",
    "print(xl.sheet_names)\n",
    "df1 = xl.parse(xl.sheet_names[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "executionInfo": {
     "elapsed": 250,
     "status": "ok",
     "timestamp": 1640887747672,
     "user": {
      "displayName": "Slava Manevich",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "03367332962160017370"
     },
     "user_tz": -180
    },
    "id": "FvC2IKPtvwbW",
    "outputId": "e278c15c-5fd4-4f3f-f7c0-190261b719d6"
   },
   "outputs": [],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1431,
     "status": "ok",
     "timestamp": 1641026268903,
     "user": {
      "displayName": "Slava Manevich",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "03367332962160017370"
     },
     "user_tz": -180
    },
    "id": "gNqy6UcR1N1o"
   },
   "outputs": [],
   "source": [
    "# вгрузил данные как надо, разбил на тест и трейн, отнормировал\n",
    "from sklearn import preprocessing\n",
    "# uni_data = df1['ln_rv_btc'].copy()\n",
    "\n",
    "uni_data = np.log(df1['rv_shk_x'].copy())\n",
    "uni_data.index = df1['Unnamed: 0']\n",
    "uni_data.head()\n",
    "xData=np.array(uni_data)\n",
    "xData = xData.reshape(len(xData),1)\n",
    "dataset=xData\n",
    "\n",
    "scaler = preprocessing.MinMaxScaler() \n",
    "\n",
    "dataset = scaler.fit_transform(dataset)\n",
    "\n",
    "#разбил на трен и тест\n",
    "coef_train_test=0.7\n",
    "\n",
    "train_size = int(len(dataset) * coef_train_test)\n",
    "test_size = len(dataset) - train_size\n",
    "train, test = dataset[0:train_size,:], dataset[train_size:len(dataset),:]\n",
    "\n",
    "# разбил трен на трен и вал\n",
    "# coef_train_val=0.9\n",
    "\n",
    "# train_size = int(len(train) * coef_train_val)\n",
    "# val_size = len(train) - train_size\n",
    "\n",
    "# train1, val= train[0:val_size,:], train[train_size:len(dataset),:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1641026271111,
     "user": {
      "displayName": "Slava Manevich",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "03367332962160017370"
     },
     "user_tz": -180
    },
    "id": "OcQInsWmlAFD"
   },
   "outputs": [],
   "source": [
    "# univariate data preparation\n",
    "from numpy import array\n",
    " \n",
    "# split a univariate sequence into samples\n",
    "#здесь sequence - это выборка, которую разбиваем, n_steps - то самое \"скользящее окно\"\n",
    "def split_sequence(sequence, n_steps):\n",
    "\tX, y = list(), list()\n",
    "\tfor i in range(len(sequence)):\n",
    "\t\t# find the end of this pattern\n",
    "\t\tend_ix = i + n_steps\n",
    "\t\t# check if we are beyond the sequence\n",
    "\t\tif end_ix > len(sequence)-1:\n",
    "\t\t\tbreak\n",
    "\t\t# gather input and output parts of the pattern\n",
    "\t\tseq_x, seq_y = sequence[i:end_ix], sequence[end_ix]\n",
    "\t\tX.append(seq_x)\n",
    "\t\ty.append(seq_y)\n",
    "\treturn array(X), array(y)\n",
    " \n",
    "# # define input sequence\n",
    "# raw_seq = train\n",
    "# # choose a number of time steps\n",
    "# n_steps = 250\n",
    "# # split into samples\n",
    "# X, y = split_sequence(raw_seq, n_steps)\n",
    "# # summarize the data\n",
    "# # for i in range(len(X)):\n",
    "# # \tprint(X[i], y[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 251,
     "status": "ok",
     "timestamp": 1641026273423,
     "user": {
      "displayName": "Slava Manevich",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "03367332962160017370"
     },
     "user_tz": -180
    },
    "id": "yR5R3ogKmQR_",
    "outputId": "f2b89b40-06bb-4411-9fa6-4489eddbd0b7"
   },
   "outputs": [],
   "source": [
    "n_steps = 100#хорошо работает при 250\n",
    "\n",
    "x_train, y_train=split_sequence(train, n_steps )\n",
    "x_test, y_test=split_sequence(test, n_steps)\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n",
    "print(x_test.shape)\n",
    "\n",
    "x_train_all=x_train.copy()\n",
    "y_train_all=y_train.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# разбил трен на трен и вал\n",
    "coef_train_val=0.9\n",
    "len_train=int(len(x_train)*coef_train_val)\n",
    "x_train1=x_train[0:len_train].copy()\n",
    "x_val=x_train[len_train:]\n",
    "x_train=x_train1\n",
    "\n",
    "y_train1=y_train[0:int(len(y_train)*coef_train_val)].copy()\n",
    "y_val=y_train[int(len(y_train)*coef_train_val):]\n",
    "y_train=y_train1\n",
    "\n",
    "print(x_train.shape)\n",
    "print(x_val.shape)\n",
    "print(y_train.shape)\n",
    "print(y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PeUNEk3CCNeQ"
   },
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "# def me(y_true, y_pred):\n",
    "def myloss(y_true, y_pred):\n",
    "    return tf.reduce_mean(tf.square(y_true - y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !pip install tensorflow\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Flatten, Convolution1D\n",
    "from keras.layers import Conv1D, MaxPooling1D\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Activation, GlobalAveragePooling1D\n",
    "from keras.layers import BatchNormalization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ТУТ заметки кода, можно вставлять кусками\n",
    "\n",
    "# СНН\n",
    "# model_m.add(Conv1D(5, 1, activation='relu', input_shape=(x_train.shape[1], x_train.shape[2])))\n",
    "# modelC.add(MaxPooling1D(pool_size=1))\n",
    "\n",
    "# просто слой с числом нейронок и активатором\n",
    "# model_m.add(Dense(50, activation='linear'))\n",
    "# дропаут, для борьбы с переобучением\n",
    "# model.add(Dropout(0.25))\n",
    "# батчевая нормализация\n",
    "# model_m.add(BatchNormalization())\n",
    "# полносвязный слой, его лучше в конце вставлять\n",
    "# model_m.add(Flatten())\n",
    "# слой с регуляризацией\n",
    "# model_m.add(Dense(64, input_dim=64, bias_regularizer=regularizers.l2(0.01), activity_regularizer=regularizers.l1(0.01)))\n",
    "# раняя остановка, чтобы не переобучаться, в мониторе писать пример \n",
    "# early_stop = EarlyStopping(monitor = 'val_loss', patience = 10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zz47DZ0QmY-R"
   },
   "source": [
    "сравнение пошло"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 959
    },
    "executionInfo": {
     "elapsed": 8947,
     "status": "ok",
     "timestamp": 1641026588044,
     "user": {
      "displayName": "Slava Manevich",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "03367332962160017370"
     },
     "user_tz": -180
    },
    "id": "s80tCytLptlg",
    "outputId": "6cf26216-6f72-45ef-a1d9-7a94715ad1fe"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import layers\n",
    "from pandas import ExcelWriter\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM, Dense, Dropout, TimeDistributed\n",
    "from keras.layers import Conv1D, MaxPooling1D, Flatten, Bidirectional\n",
    "from keras.layers import Input, Flatten, Activation, Reshape, RepeatVector, Concatenate\n",
    "from keras.layers import Flatten, Convolution1D\n",
    "from keras.layers import Conv1D, MaxPooling1D\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Activation, GlobalAveragePooling1D\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "from keras import regularizers\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "activation_functions=['tanh', 'linear', 'relu', 'softmax', 'elu', 'selu', 'softplus', 'softsign', 'sigmoid', 'hard_sigmoid', 'exponential', 'LeakyReLU', 'PReLU', 'ThresholdedReLU']\n",
    "# activation_functions_n=['selu', 'softplus', 'softsign', 'sigmoid', 'hard_sigmoid', 'exponential', 'LeakyReLU', 'PReLU', 'ThresholdedReLU']\n",
    "\n",
    "# loss_f=['mae', 'mse']\n",
    "# T_F=['True', 'False']\n",
    "\n",
    "# all_logir=pd.DataFrame({ })\n",
    "i=0\n",
    "all_logir_pred=pd.DataFrame()\n",
    "all_logir_mae=pd.DataFrame()\n",
    "all_logir_mse=pd.DataFrame()\n",
    "all_logir_me=pd.DataFrame()\n",
    "\n",
    "testY = scaler.inverse_transform(y_test)\n",
    "testY=testY.reshape(testY.shape[0])\n",
    "all_logir_pred['testY']=testY\n",
    "for a_1 in activation_functions:\n",
    "    for d_1 in np.arange(0, 0.3, 0.1):\n",
    "        for a_2 in activation_functions:\n",
    "            for d_2 in np.arange(0, 0.3, 0.1):\n",
    "                for a_3 in activation_functions:\n",
    "                                            \n",
    "                    i=i+1\n",
    "                    name_col=(str(a_1)+'-'+str(d_1)+'-'+\n",
    "                            str(a_2)+'-'+str(d_2)+'-'+str(a_3)+'-'+str(i))\n",
    "                            \n",
    "#                     all_logir[name_col]=activation_functions\n",
    "                                            \n",
    "                    model_m = Sequential()                        \n",
    "                    model_m.add(Dense(1, input_shape=(x_train.shape[1], x_train.shape[2])))#входной нейрон\n",
    "\n",
    "                    model_m.add(LSTM(64,return_sequences = True, activation=a_1, input_shape = (x_train.shape[1], x_train.shape[2])))\n",
    "                    model_m.add(Dropout(d_1))\n",
    "                    model_m.add(LSTM(32, activation=a_2, input_shape = (x_train.shape[1], x_train.shape[2])))\n",
    "                    model_m.add(Dropout(d_2))\n",
    "\n",
    "                    model_m.add(Dense(10, activation=a_3))\n",
    "                    model_m.add(Flatten())\n",
    "                    model_m.add(Dense(1, activation='linear'))\n",
    "\n",
    "                    model_m.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "                    early_stop = EarlyStopping(monitor = 'loss', patience = 5)\n",
    "\n",
    "                    history = model_m.fit(x_train, \n",
    "                                                            y_train, \n",
    "                                                            epochs=20, \n",
    "                                                            batch_size=15, #для борьбы с затухающим градиентом, как часто перетасовывать говну данных\n",
    "                                                            verbose=1,\n",
    "                                                            shuffle = False,\n",
    "                                                            callbacks = [early_stop],\n",
    "                                                            validation_data=(x_val, y_val)\n",
    "                                                            )\n",
    "                    predicted = model_m.predict(x_test)\n",
    "                    testPredict = scaler.inverse_transform(predicted)\n",
    "                    testPredict=testPredict.reshape(testPredict.shape[0])\n",
    "                    all_logir_pred[str(name_col)]=testPredict\n",
    "\n",
    "# predicted.reshape(predicted.shape[0])\n",
    "                    me=testY-testPredict\n",
    "                    mae=abs(testY-testPredict)\n",
    "                    mse=(testY-testPredict)**2\n",
    "                            \n",
    "                \n",
    "#                     testY.reshape(testY.shape[0])\n",
    "                    all_logir_me[str(name_col)]=me.reshape(me.shape[0])\n",
    "                    all_logir_mae[str(name_col)]=mae.reshape(mae.shape[0])\n",
    "                    all_logir_mse[str(name_col)]=mse.reshape(mse.shape[0])\n",
    "                    \n",
    "                    if i % 200 == 0:\n",
    "                        writer_pred=pd.ExcelWriter('all_logir_pred.xlsx')\n",
    "                        all_logir_pred.to_excel(writer_pred)\n",
    "                        writer_pred.save()\n",
    "#                         writer_pred.close()\n",
    "                        \n",
    "                        writer_me=pd.ExcelWriter('all_logir_me.xlsx')\n",
    "                        all_logir_me.to_excel(writer_me)\n",
    "                        writer_me.save()\n",
    "#                         writer_me.close()\n",
    "                        \n",
    "                        writer_mae=pd.ExcelWriter('all_logir_mae.xlsx')\n",
    "                        all_logir_mae.to_excel(writer_mae)\n",
    "                        writer_mae.save()\n",
    "#                         writer_mae.close()\n",
    "                        \n",
    "                        writer_mse=pd.ExcelWriter('all_logir_mse.xlsx')\n",
    "                        all_logir_mse.to_excel(writer_mse)\n",
    "                        writer_mse.save()\n",
    "#                         writer_mse.close()\n",
    "                        \n",
    "                    print(i)\n",
    "                \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import ExcelWriter\n",
    "\n",
    "print(i)\n",
    "writer_pred=pd.ExcelWriter('all_logir_pred.xlsx')\n",
    "all_logir_pred.to_excel(writer_pred)\n",
    "writer_pred.save()\n",
    "writer_pred.close()\n",
    "                        \n",
    "writer_me=pd.ExcelWriter('all_logir_me.xlsx')\n",
    "all_logir_me.to_excel(writer_me)\n",
    "writer_me.save()\n",
    "writer_me.close()\n",
    "                        \n",
    "writer_mae=pd.ExcelWriter('all_logir_mae.xlsx')\n",
    "all_logir_mae.to_excel(writer_mae)\n",
    "writer_mae.save()\n",
    "writer_mae.close()\n",
    "                        \n",
    "writer_mse=pd.ExcelWriter('all_logir_mse.xlsx')\n",
    "all_logir_mse.to_excel(writer_mse)\n",
    "writer_mse.save()\n",
    "writer_mse.close()\n",
    "\n",
    "end_time=time.time() - start_time    \n",
    "print(end_time)\n",
    "print(i)\n",
    "print(all_logir_pred)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOU/PZRjWdHtZLJn/X5bccw",
   "collapsed_sections": [],
   "mount_file_id": "18rpzGo5XmWRKJ9Fsb_4BhlAKhWvA2Rjq",
   "name": "Еще одна нейронка.ipynb",
   "provenance": [
    {
     "file_id": "18rpzGo5XmWRKJ9Fsb_4BhlAKhWvA2Rjq",
     "timestamp": 1640938927736
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
